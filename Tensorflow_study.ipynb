{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "\n",
    "model.compile(optimizer='sgd', loss = 'mean_squared_error')\n",
    "\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype = float)\n",
    "ys = np.array([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype = float)\n",
    "\n",
    "model.fit(xs, ys, epochs = 500)\n",
    "\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('acc')>0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()            \n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])\n",
    "\n",
    "training_images = training_images/ 255.0\n",
    "test_images = test_images/ 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(128, activation=tf.nn.relu), #dense : add a layer of neurons\n",
    "                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs = 5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = misc.ascent()\n",
    "\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "\n",
    "i_transformed = np.copy(i)\n",
    "size_x = i_transformed.shape[0]\n",
    "size_y = i_transformed.shape[1]\n",
    "\n",
    "filter = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "weight = 1\n",
    "\n",
    "for x in range(1,size_x-1):\n",
    "    for y in range(1,size_y-1):\n",
    "        output_pixel = 0.0\n",
    "        output_pixel = output_pixel+(i[x-1, y-1]*filter[0][0])\n",
    "        output_pixel = output_pixel+(i[x, y-1]*filter[0][1])\n",
    "        output_pixel = output_pixel+(i[x+1,y-1]*filter[0][2])\n",
    "        output_pixel = output_pixel+(i[x-1,y]*filter[1][0])\n",
    "        output_pixel = output_pixel+(i[x, y]* filter[1][1])\n",
    "        output_pixel = output_pixel+(i[x+1, y]*filter[1][2])\n",
    "        output_pixel = output_pixel+(i[x-1, y+1]*filter[2][0])\n",
    "        output_pixel = output_pixel+(i[x, y+1]*filter[2][1])\n",
    "        output_pixel = output_pixel+(i[x+1, y+1]* filter[2][2])\n",
    "        output_pixel = output_pixel * weight\n",
    "        if(output_pixel<0):\n",
    "            output_pixel = 0\n",
    "        if(output_pixel>255):\n",
    "            output_pixel = 255\n",
    "        i_transformed[x,y] = output_pixel\n",
    "        \n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(i_transformed)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "new_x = int(size_x/2)\n",
    "new_y = int(size_y/2)\n",
    "newImage = np.zeros((new_x, new_y))\n",
    "\n",
    "for x in range(0, size_x, 2):\n",
    "    for y in range(0, size_y, 2):\n",
    "        pixels = []\n",
    "        pixels.append(i_transformed[x,y])\n",
    "        pixels.append(i_transformed[x+1,y])\n",
    "        pixels.append(i_transformed[x,y+1])\n",
    "        pixels.append(i_transformed[x+1,y+1])\n",
    "        pixels.sort(reverse = True)\n",
    "        newImage[int(x/2), int(y/2)] = pixels[0]\n",
    "        \n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(newImage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimzer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs = 5)\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs = 5)\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))\n",
    "\n",
    "print(test_labels[:100])\n",
    "\n",
    "f, axarr = plt.subplots(3, 4)\n",
    "FIRST_IMAGE = 0\n",
    "SECOND_IMAGE = 23\n",
    "THIRD_IMAGE = 28\n",
    "CONVOLUTION_NUMBER = 6\n",
    "\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0,x].imshow(f1[0,:,:,CONVOLUTION_NUMBER], cmap = 'inferno')\n",
    "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1,x].imshow(f2[0,:,:,CONVOLUTION_NUMBER], cmap = 'inferno')\n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0,:,:,CONVOLUTION_NUMBER], cmap = 'inferno')\n",
    "    axarr[2,x].grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "#file source\n",
    "#https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
    "\n",
    "local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "zip_ref.close()\n",
    "\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')\n",
    "\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])\n",
    "\n",
    "print('total training horse images: ', len(os.listdir(train_horse_dir)))\n",
    "print('total training human images: ', len(os.listdir(train_human_dir)))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "pic_index = 0\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows*4)\n",
    "\n",
    "pic_index += 8\n",
    "next_horse_pix = [os.path.join(train_horse_dir, fname)\n",
    "                 for fname in train_horse_names[pic_index-8:pic_index]]\n",
    "next_human_pix = [os.path.join(train_human_dir, fname)\n",
    "                 for fname in train_human_names[pic_index-8::pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_horse_pix + next_human_pix):\n",
    "    \n",
    "    if i+1 > nrows * ncols:\n",
    "        break\n",
    "    sp = plt.subplot(nrows, ncols, i+1)\n",
    "    sp.axis('On')\n",
    "    \n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    #512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    #Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horse or human')\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = RMSprop(lr = 0.001),\n",
    "             metircs = ['acc'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "#Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "'./horse-or-human/',\n",
    "target_size = (300, 300),\n",
    "batch_size = 64,\n",
    "class_mode = 'binary')\n",
    "\n",
    "history = model.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch = 8,\n",
    "epochs = 15,\n",
    "verbose = 1) # out of memory, #batch size was too big. 128 -> 64\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size = (300, 300))\n",
    "x = img_to_array(img) #numpy array with shape(150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "        #just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        n_features = feature_map.shape[-1]\n",
    "        #the feautre map has shape(1, size, size, n_features)\n",
    "        size = feature_map.shape[1]\n",
    "        #we will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size*n_features))\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            #Postprocess the feature to make it visually palatable\n",
    "            x = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            #we'll tile each filter into this big horizontal grid\n",
    "            display_grid[:, i*size : (i+1)*size] = x\n",
    "        #display the grid\n",
    "        \n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize = (scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(True)\n",
    "        plt.imshow(display_grid, aspect = 'auto', cmap = 'viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "\n",
    "#file source : https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "\n",
    "local_zip = './kagglecatsanddogs_3367a.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "print(len(os.listdir('./PetImages/Cat/')))\n",
    "print(len(os.listdir('./PetImages/Dog/')))\n",
    "\n",
    "try:\n",
    "    os.mkdir('./cats-v-dogs')\n",
    "    os.mkdir('./cats-v-dogs/training')\n",
    "    os.mkdir('./cats-v-dogs/testing')\n",
    "    os.mkdir('./cats-v-dogs/training/cats')\n",
    "    os.mkdir('./cats-v-dogs/training/dogs')\n",
    "    os.mkdir('./cats-v-dogs/testing/cats')\n",
    "    os.mkdir('./cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, is ignoring.\")\n",
    "            \n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[:testing_length]\n",
    "    \n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "        \n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "        \n",
    "CAT_SOURCE_DIR = \"./PetImages/Cat/\"        \n",
    "TRAINING_CATS_DIR = \"./cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"./cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"./PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"./cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"./cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
    "\n",
    "print(len(os.listdir('./cats-v-dogs/training/cats')))\n",
    "print(len(os.listdir('./cats-v-dogs/training/dogs')))\n",
    "print(len(os.listdir('./cats-v-dogs/testing/cats')))\n",
    "print(len(os.listdir('./cats-v-dogs/testing/dogs')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = RMSprop(lr=0.001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "\n",
    "TRAINING_DIR = \"./cats-v-dogs/training/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                   batch_size = 30,\n",
    "                                                   class_mode = 'binary',\n",
    "                                                   target_size = (150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"./cats-v-dogs/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                             batch_size = 30,\n",
    "                                                             class_mode = 'binary',\n",
    "                                                             target_size = (150, 150))\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             epochs = 5,\n",
    "                             verbose = 1,\n",
    "                             validation_data = validation_generator)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()\n",
    "\n",
    "import numpy as np\n",
    "#from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#uploaded = files.upload()\n",
    "PREDICT_DIR = './predict/'\n",
    "\n",
    "#path = []\n",
    "\n",
    "for filenames in os.listdir(PREDICT_DIR):\n",
    "    \n",
    "    #predicting images\n",
    "    #path.append(PREDICT_DIR + filenames)\n",
    "    path = PREDICT_DIR + filenames\n",
    "    img = image.load_img(path, target_size = (150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    #classes = model.predict(images, batch_size = 10)\n",
    "    classes = model.predict(images, batch_size = 10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(filenames + \" is a dog\")\n",
    "    else:\n",
    "        print(fnlenames + \" is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
